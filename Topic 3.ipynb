{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd  # type: ignore\n",
    "import numpy as np\n",
    "\n",
    "df60 = pd.read_csv(\"MSJO 60 01-03 2023.csv\", delimiter=\";\")\n",
    "df900 = pd.read_csv(\"MSJO 900 01-03 2023.csv\", delimiter=\";\")\n",
    "print(df60)\n",
    "\n",
    "# Basis Datansatz sortieren\n",
    "df_sorted = df60.sort_values(by=[\"MESS_ID\", \"VALUEDATE\"], ascending=[True, True])\n",
    "# df_sorted.to_csv(\"sortierte_datei.csv\", index=False)\n",
    "\n",
    "# Drop rows with any missing values in MESS_ID, VALUEDATE, or PVALUE\n",
    "df60 = df60.dropna(subset=[\"MESS_ID\", \"VALUEDATE\", \"PVALUE\"], how=\"any\")\n",
    "df900 = df900.dropna(subset=[\"MESS_ID\", \"VALUEDATE\", \"PVALUE\"], how=\"any\")\n",
    "\n",
    "# Drop rows with Pvalue = 0\n",
    "df60 = df60[df60[\"PVALUE\"] != \"0\"]\n",
    "df900 = df900[df900[\"PVALUE\"] != \"0\"]\n",
    "\n",
    "# Drop Duplicates\n",
    "duplicates = df60.duplicated().sum()\n",
    "df60.drop_duplicates(inplace=True)\n",
    "duplicates = df900.duplicated().sum()\n",
    "df900.drop_duplicates(inplace=True)\n",
    "\n",
    "# Set PVLAUE to float\n",
    "df60[\"PVALUE\"] = df60[\"PVALUE\"].str.replace(\",\", \".\").astype(float)\n",
    "df900[\"PVALUE\"] = df900[\"PVALUE\"].str.replace(\",\", \".\").astype(float)\n",
    "\n",
    "# Quartile berechnen\n",
    "Q1_60 = df60[\"PVALUE\"].quantile(0.25)\n",
    "Q3_60 = df60[\"PVALUE\"].quantile(0.75)\n",
    "IQR60 = Q3_60 - Q1_60\n",
    "Q1_900 = df900[\"PVALUE\"].quantile(0.25)\n",
    "Q3_900 = df900[\"PVALUE\"].quantile(0.75)\n",
    "IQR900 = Q3_900 - Q1_900\n",
    "\n",
    "# Definiere die Schwellenwerte\n",
    "obere_schwelle_60 = Q3_60 + 1.5 * IQR60\n",
    "print(obere_schwelle_60)\n",
    "obere_schwelle_900 = Q3_900 + 1.5 * IQR900\n",
    "print(obere_schwelle_900)\n",
    "\n",
    "# Filtere die Zeilen\n",
    "df_filtered_60 = df60[(df60[\"PVALUE\"] >= obere_schwelle_60)]\n",
    "df_filtered_900 = df900[(df60[\"PVALUE\"] >= obere_schwelle_900)]\n",
    "\n",
    "# Gefiltertes DataFrame anzeigen\n",
    "print(\"Gefiltertes DataFrame:\")\n",
    "print(df_filtered_60)\n",
    "print(df_filtered_900)\n",
    "\n",
    "# New CSV File\n",
    "# df.to_csv(\"cleaned.csv\", index=False)\n",
    "# df_filtered.to_csv(\"test.csv\", index=False)\n",
    "\n",
    "# Calculate mean\n",
    "pvalue_mean = df60[\"PVALUE\"].mean()\n",
    "\n",
    "# Drop outliers\n",
    "df60 = df60[(df60[\"PVALUE\"] <= obere_schwelle_60)]\n",
    "df900 = df900[(df900[\"PVALUE\"] <= obere_schwelle_900)]\n",
    "\n",
    "# ------------------------------------------------\n",
    "\n",
    "# from sklearn.linear_model import LinearRegression\n",
    "# from sklearn.model_selection import train_test_split\n",
    "\n",
    "# # Convert VALUEDATE to datetime and extract the date as a numerical feature\n",
    "# df[\"VALUEDATE\"] = pd.to_datetime(df[\"VALUEDATE\"])\n",
    "# df[\"DATEORDINAL\"] = df[\"VALUEDATE\"].apply(lambda date: date.toordinal())\n",
    "\n",
    "# # Split the data into training and testing sets\n",
    "# X_train, X_test, y_train, y_test = train_test_split( df[[\"DATEORDINAL\"]], df[\"PVALUE\"], test_size=0.2, random_state=42 )\n",
    "\n",
    "# # Time series forecasting\n",
    "# model = LinearRegression()\n",
    "# model.fit(X_train, y_train)\n",
    "\n",
    "# # Print the coefficient and intercept of the model\n",
    "# print(f\"Coefficient: {model.coef_}\")\n",
    "# print(f\"Intercept: {model.intercept_}\")\n",
    "\n",
    "#--------------------------------------------------\n",
    "\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "df60['VALUEDATE'] = pd.to_datetime(df60['VALUEDATE'])  # Convert 'date' column to datetime\n",
    "df60.set_index('VALUEDATE', inplace=True) \n",
    "df900['VALUEDATE'] = pd.to_datetime(df900['VALUEDATE'])  # Convert 'date' column to datetime\n",
    "df900.set_index('VALUEDATE', inplace=True) \n",
    "\n",
    "df60['avg_value'] = df60.mean(axis=1)\n",
    "df900['avg_value'] = df900.mean(axis=1)\n",
    "\n",
    "# Resample 60-second data to 15-minute intervals\n",
    "df_60s_resampled = df60['avg_value'].resample('15T').mean()\n",
    "df_60s_resampled = df_60s_resampled.fillna(df_60s_resampled.mean())\n",
    "\n",
    "# Train-Test Split\n",
    "train_size = int(len(df_60s_resampled) * 0.8)\n",
    "train_60s, test_60s = df_60s_resampled[:train_size], df_60s_resampled[train_size:]\n",
    "train_15min, test_15min = df900[:train_size], df900[train_size:]\n",
    "\n",
    "# Train ARIMA model on 60-second resampled data\n",
    "arima_60s = ARIMA(train_60s, order=(5, 1, 0))\n",
    "arima_60s_fit = arima_60s.fit()\n",
    "\n",
    "# Train ARIMA model on 15-minute data\n",
    "arima_15min = ARIMA(train_15min, order=(5, 1, 0))\n",
    "arima_15min_fit = arima_15min.fit()\n",
    "\n",
    "# Forecasting\n",
    "arima_60s_forecast = arima_60s_fit.forecast(steps=len(test_60s))\n",
    "arima_15min_forecast = arima_15min_fit.forecast(steps=len(test_15min))\n",
    "\n",
    "# Evaluation\n",
    "arima_60s_mse = mean_squared_error(test_60s, arima_60s_forecast)\n",
    "arima_15min_mse = mean_squared_error(test_15min, arima_15min_forecast)\n",
    "\n",
    "print(f'ARIMA 60-second resampled MSE: {arima_60s_mse}')\n",
    "print(f'ARIMA 15-minute MSE: {arima_15min_mse}')\n",
    "\n",
    "#-------------------------------------------"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
